---
layout: post
title:  "Sonar to Image 연구 프로젝트 후기"
tags: 호주 DL GAN 연구 research
comments: true
---

2019년 11월부터 2020년 2월까지 호주 QUT 대학교에서 진행한 10주 연구 프로젝트 'Sonar to Image'에 관한 후기다.

[깃허브](https://github.com/json9512/sonarToimage)

대학교 2학년 마치고 여름 방학 동안 10주 연구 프로젝트를 한 적이 있다. 

연구 팀은 지도 교수 2명 학생 2명 이렇게 4인이었고 사실상 연구 경험을 '맛 보기' 하는 프로젝트였다.

# 연구 내용
연구의 핵심은 가상 공간 (VR)에 해저 환경을 딥러닝을 이용해 구현하는 것이었다. 임의의 환경을 만드는 것이 아닌 실존하는 해저 지형을 딥러닝이 만들어내는 것이었다. 

궁극적인 목표는 잠수함이 해저를 탐험 할 때 sonar로 지형 지물의 존재여부를 알게 되는데, 이때 가상의 스크린에 바로 지형이 펄쳐지도록 하는 것이 이 연구의 마지막 단계라고 했다.

이 부분은 크게 2가지로 나뉘어졌었다. 
1. 수집된 sonar와 제한적인 image를 가지고 딥러닝 모델을 구현하는 것
2. 딥러닝이 생성한 데이터를 (Unity나 Unreal) VR 환경에 구축하는 것

여기서 나는 1번을 하게 되었다.

****
지도 교수님의 도움으로 어떤 모델을 만들어야 할지 알아보다가 **GAN** 모델로 정하게 되었다. 

**GAN** 이란 Generative Adversarial Network의 약자인데, 쉽게 말하면 두 개의 딥러닝 네트워크가 서로 상호작용하며 주어진 학습 데이터를 바탕으로 새로운 데이터를 만들어 낼 수 있는 모델이다. 

구체적인 내용은 [모델 학습](###모델-학습)에서 설명하겠다. 

# 연구 일지
딥러닝, 머신러닝으로 모델을 만들 때 크게 3 가지가 중요하다고 볼 수 있는데:
1. Data preprocessing 데이터 전처리
2. Model training 모델 학습
3. Model evaluation 모델 평가

이 중 데이터 전처리 과정이 모델의 능력을 결정한다고 볼 수 있다. 아무리 모델이 뛰어나도 쓰레기 데이터가 들어가면 쓰레기 데이터가 나온다. 

### 데이터 전처리 과정

일단 데이터는 ROS 형식으로 저장이 되어 있었고, 거기서 유용한 데이터를 찾고 엑셀화 시키는 것에만 1주~2주 정도 소모됐다. 

내게 주어진 데이터는:
1. 기계가 전 방위 1~2초 단위로 수집한 sonar 데이터와
2. 기계 하단부 카메라에서 수집한 해저 땅? 사진들 300백 장 정도가 다였다. 

일단 사진 데이터가 하단부 밖에 촬영을 못했기 때문에 실제로 모델을 학습 시킬 때 사용할 수 있었던 데이터는 sonar가 하단부 카메라 각 안에 들어올때 밖에 없었다. 

이후 카메라 각 안에 들어오는 sonar 수치를 binary map으로 찍어서 이미지화 시켰다. 

그리고 기존 사진 300백 장도 살펴보니 Spotlight effect (사진 중앙만 밝은 현상)이 심해서 이걸 없애는 알고리즘을 찾느라 또 시간을 많이 보냈다.

CLAHE라는 알고리즘으로 Spotlight effect를 지운 후 마침내 모델 학습을 위한 `[sonar binary map, 카메라가 수집한 사진]` 을 만들었다. 

### 모델 학습

**GAN** 은 Generator, Discriminator라는 2개의 네트워크가 서로 상호작용한다. 간단히 설명하면 Generator는 주어진 X 정보를 활용해 Y 정보를 제작한다, 이후 Discriminator는 제작된 Y가 실제 Y인지 분별하는 역할을 한다. 

Generator는 궁극적으로 Discriminator를 속일 수 있을 만한 데이터를 만들게 되고, Generator가 만든 Y 데이터가 모델이 만들어낸 데이터라고 보면 된다.

즉 이 연구에서는 Generator 에게 `sonar binary map`을 주고 `카메라가 수집한 사진` 같은 데이터를 만들어내라고 하는 것이다. 그러면 Discriminator는 실제 `카메라가 수집한 사진`과 Generator가 만든 `카메라가 수집한 사진`을 비교하며 유사도 점수를 준다.  

모델 자체는 [pix2pix 모델](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py)을 조금 더 경량화 시켜서 사용했고 완성도는 딥러닝에 대한 지식이 없을 때 만든거라 뛰어나지 않다. 

### 모델 평가

확실히 처음 딥러닝을 접할 때여서 Overfitting이 뭔지 어떻게 해결하는지 잘 몰랐다.

즉, 모델 자체의 완성도는 좋지 않다. 그냥 이런 모델을 시도해 봤다 정도로 보면 되겠다. 

# 결과 

사진 한장을 보고 어떤 사진이 모델이 만들어낸 것인지 분별을 해보자.

<img src="{{ site.baseurl }}/images/gan-result-test.png" class="align-center" alt=""/>

실제 사진과 모델이 만든 사진에 차이가 보이긴 보인다.
처음 모델이 사진을 만들어 냈을 때 상당히 신기했다.

<img src="{{ site.baseurl }}/images/gan-result.png" class="align-center" alt=""/>

주어진 `sonar binary map` 이 제일 윗 줄

Generator가 만들어낸 `카메라가 수집한 사진`이 중간 줄

실제 `카메라가 수집한 사진`이 마지막 줄이다.

위 사진은 대조할 `카메라가 수집한 사진`이 있는 sonar 각에 대한 학습 결과고 실제로 저 모델을 사용해서 `카메라가 수집한 사진`이 없는 sonar 각 까지 모델로 만들어서 이어보면 상당히 흥미로운 결과를 볼 수 있다. 

*궁금하면 [여기](https://github.com/json9512/sonarToimage/blob/master/sample/imgs/image.png) 에 있다*


처음 도전한 딥러닝이었고 데이터 전처리, 모델 학습 및 평가 과정이 상당히 부족한 프로젝트였지만 이 계기를 통해 나는 인공지능에 대해 좀 더 관심을 가지게 되었다. 그리고 이후 머신러닝/딥러닝 과목을 이수하게 되었다. 