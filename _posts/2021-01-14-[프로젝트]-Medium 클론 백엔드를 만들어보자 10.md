---
layout: post
title:  "[프로젝트] Medium 클론 백엔드를 만들어보자 -10"
tags: project
excerpt: "Medium 클론 백엔드를 설계부터 배포까지 기록하는 시리즈"
comments: true
---

**목차**
1. [Medium 클론 백엔드를 만들어보자 -1]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-1/)
2. [Medium 클론 백엔드를 만들어보자 -2]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-2/)
3. [Medium 클론 백엔드를 만들어보자 -3]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-3/)
4. [Medium 클론 백엔드를 만들어보자 -4]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-4/)
5. [Medium 클론 백엔드를 만들어보자 -5]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-5/)
6. [Medium 클론 백엔드를 만들어보자 -6]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-6/)
7. [Medium 클론 백엔드를 만들어보자 -7]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-7/)
8. [Medium 클론 백엔드를 만들어보자 -8]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-8/)
9. [Medium 클론 백엔드를 만들어보자 -9]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-9/)
10. Medium 클론 백엔드를 만들어보자 -10
11. [Medium 클론 백엔드를 만들어보자 -11]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-11/)

# 이전 포스트에서 . . .
- AWS로 서버를 배포 해봄

# 이 포스트는 . . .
- 배포 과정을 자동화 시도

# Docker 이미지 배포 방법
현재까지는 Docker Hub에 이미지를 자동배포를 했었다. 하지만 전 포스트에서 AWS ECR로 이미지를 배포하는 방법을 알았으니 CI/CD에서도 AWS ECR로 자동 배포를 하려고 한다.

아마존 [블로그](https://aws.amazon.com/ko/blogs/containers/create-a-ci-cd-pipeline-for-amazon-ecs-with-github-actions-and-aws-codebuild-tests/) 글을 참고를 하자. 이미 잘 설명이 돼있다.

AWS 개인 정보를 secrets에 저장 시킨 뒤 `ci-docker-cd.yml`에서 AWS ECR로 이미지를 배포하도록 수정을 했다. 

# AWS 배포 자동화

하루 정도의 시간을 투자한 결과, Github Actions로 AWS에 서버 배포 자동화를 성공 시켰다. 

<img src="{{ site.baseurl}}/images/awssetup.png" class="align-center" alt=""/>
<img src="{{ site.baseurl}}/images/awssetup2.png" class="align-center" alt=""/>

간략하게 하루 동안 삽질했던 문제점들을 나열하자면:
1. Github Actions workflow에서 Docker 이미지내로 환경변수 전달하기
2. AWS RDS와 AWS EC2 연결하기
3. AWS RDS와 AWS EC2내에 Docker 컨테이너와 연결하기
4. 새로운 commit push/pr 시, ECS에 기존 인스턴스가 남아 있어서 자동 배포 되지 않는 문제

### 해결 방법
#### 1. Github Actions workflow에서 Docker 이미지내로 환경변수 전달하기

자동화를 많이 해본 적은 없지만 현재까지 자동화를 하면서 가장 문제를 많이 일으켰던 부분은 환경변수를 설정하는 일이다.

현재 이 포스트를 작성하는 시점, 고 코드는 AWS RDS에 연결하는 기능까지 구현하고 난 직후다. 개발을하다가 보면 여러 환경변수를 사용해서 중요한 정보들을 관리한다. 동시에 Github에 push될 때 중요한 정보가 노출이 되지 않게 해야한다. 

여기서 말하는 중요한 정보란, 외부에 노출이 되었을 때 서버에 막대한 피해를 끼칠 수 있는 정보를 뜻한다. 예를 들면 관리자 비밀번호, 개인정보, 기타등등 있겠다.

수정 전 중요한 정보를 취급하는 방식은 다음과 같았다.
1. `viper.yml` 파일에 중요한 정보를 저장한다
2. 고 서버 내에서는 `viper`라는 패키지를 써서 저장된 `viper.yml`파일에서 환경변수를 읽는다
3. `.gitignore`에 `viper.yml`을 작성하여 Github에 중요한 정보가 노출되지 않게 한다. 

이렇게 정보를 관리하게되면 기존에 만들어 놓았던 Github Actions의 Workflow가 실패한다. 정확히는 각 OS에서 서버를 실행 시킬 때 문제가 생긴다. 이유는 `viper.yml`이 Github에 없기 때문이다.

<img src="{{ site.baseurl}}/images/testfail.png" class="align-center" alt=""/>

이 문제를 해결하려면 다음과 같은 방식들이 있다:
1. `viper.yml`파일을 Github에 올려서 Github Actions가 쓸 수 있게함
2. 코드를 수정해서 `viper.yml` 의존성을 없애고, 환경변수를 Github secret에 저장함
3. Dockerfile이나 `ci-docker-cd.yml` workflow 파일에서 환경 변수를 담은 `viper.yml` 파일을 생성함

Github Actions workflow `ci-docker-cd.yml`파일에서 환경변수를 Github에 노출하지 않고 `Dockerfile`에 전달 하려면 `Dockerfile` 내에서 `ENV`를 쓰면 된다. 하지만 나는 혹시 몰라서 `ARG`로 필요한 변수들을 직접 다 생성해서 `Dockerfile`에 전달했다.

여러가지 시행착오 끝에 현재 해결안을 살펴보면 다음과 같다 (2번 방식을 택함).
- `viper` 대신 `godotenv` 패키지를 활용해서 `viper.yml` 파일 의존성을 없앴다
- Github Secrets에 환경변수 저장
- workflow yaml 파일에서 `secrets.XXX`로 호출
- `Dockerfile` 을 빌드 할 때 환경변수를 `ARG`로 주는 방식
- 유닛 테스트에 환경변수가 제대로 로드되는지 확인하는 테스트를 작성했다

위 수정사항을 반영하는 시작점이 되는 [commit](https://github.com/json9512/mediumclone-backendwithgo/commit/8d14e0c57f47937d2ea0fd5113e5cc899961eb69)이다. 그리고 테스트 결과를 보면 Workflow가 다시 잘 작동하는 것을 볼 수 있다.

<img src="{{ site.baseurl}}/images/testsuccess.png" class="align-center" alt=""/>

위 유닛테스트는 CI/CD 파이프라인에서 코드만 테스트하는 것이다. 실제로 Docker 이미지가 생성된 후 컨테이너에서의 테스트는 하지 않았다. ~~지금은 하는 방법을 모른다~~

예시:

- Github Secrets에 환경변수 설정:
<img src="{{ site.baseurl}}/images/githubsecretsexample.png" class="align-left" alt=""/>
- Workflow yaml에서 `secrets.XXX`로 호출:
<img src="{{ site.baseurl}}/images/dockerargsexample.png" class="align-center" alt=""/>
- Dockerfile `ARG`, `ENV` 사용해서 환경변수 사용:
<img src="{{ site.baseurl}}/images/dockerfileexample.png" class="align-center" alt=""/>

물론 이보다 효율적인 방법이 있을 것이다. 가령 Github Actions `job` 환경에 혹은 `global`하게 변수를 선언 하는 방법있다.

#### 2. AWS RDS와 AWS EC2 연결하기
AWS RDS와 AWS EC2간 연결이 자동으로 될 거라고 생각했지만 아니었다.

기본적으로 AWS RDS를 만들 때 `Public Access`가 가능하게 만들어야 외부에서 접속이 가능하다. 이 기능을 꺼 놓으면 같은 네트워크 안에 있는 instance들만 연결 할 수 있다고 한다. 

그리고 포트 설정도 유심히 봐줘야한다. Postgresql 포트의 기본 값인 `5432` 포트를 사용했다.

이후 AWS RDS 와 AWS EC2의 보안 그룹에서 인바운드, 아웃바운드 규칙에 `5432` 포트를 통과 할 수 있게 설정을 해야한다.

#### 3. AWS RDS와 AWS EC2내에 Docker 컨테이너와 연결하기
예상했던 것처럼 AWS RDS와 EC2내 Docker간 통신이 가장 큰 문제였다.

AWS RDS와 컨테이너가 성공적으로 연결이 되는 것을 확인하려면 사실 ec2 내에서 터미널로 확인해야한다. 

다른 방법으로는 배포된 컨테이너가 잘 작동하는지 브라우저나 AWS 콘솔을 통해 확인하는 방법이 있다. 

나는 브라우저와 콘솔을 주로 사용하다가 도저히 디버깅이 안돼서 EC2에 SSH로 연결 후 터미널로 디버깅을 했다. 

알고봤더니 Dockerfile에서 `5432` 포트를 열어 놓지 않아서 컨테이너 내에 Go 서버가 죽어있던 것이었다. (코드가 DB connection이 안되면 로그를 내뱉으면서 죽는 방식이기 때문이다)

Dockerfile에 `5432` 포트를 열어주고 `host` EC2의 포트 역시 개방해주니 바로 해결됐다.

이 문제를 해결하는데 가장 오래 걸렸다.

#### 4. 새로운 commit push/pr 시, ECS에 기존 인스턴스가 남아 있어서 자동 배포 되지 않는 문제
Github에 새로운 PR을 진행을 해봤는데 ECS에 있던 기존 인스턴스에 새로운 작업이 실행되지 않는 문제를 발견했다. 

무슨 말이냐면, CI/CD 파이프라인이 제대로 구축이 됐다면 Github에 PR을 하는 순간 AWS ECR에 새로운 이미지가 배포되고 그 배포된 이미지를 사용해서 새로운 컨테이너가 EC2안에 구축이 돼야한다. 

유저 입장에서는 Go 서버를 브라우저로 방문했을 때, 업데이트 된 서버가 응답을 해야하는 것이었다.

하지만 위 과정이 되지 않았다.

이 부분도 몇번의 구글링 끝에 ECS의 `minimum healthy percent`와 `maximum percent` 설정을 손보면 되는 것이었다. 내가 원하는 것은 ECS가 1개의 인스턴스를 구동하며, 새 이미지가 배포되면 기존 컨테이너를 없애고 새 컨테이너를 만드는 것이었다.

이 [스택오버플로우](https://stackoverflow.com/questions/40731143/what-is-the-minimum-healthy-percent-and-maximum-percent-in-amazon-ecs) 글을 참고해서 1개의 인스턴스로 롤링 배포를 원활하게 작동하게끔 구축했다.

# 마무리
정리를 하자면:
- AWS ECR로 이미지 배포, AWS ECS로 EC2 구동 후 컨테이너 배포까지 Github Actions로 자동화 시켰다

물론 지금 설정한 Workflow는 추후에 바뀔 가능성이 높다. 하지만 당분간은 개발에 집중해도 될 것 같다.

[다음 포스트]({{site.baseurl}}/프로젝트-Medium-클론-백엔드를-만들어보자-11/)부터는 RESTful API를 만드는 과정에 대해 알아보자.

여담으로 개발자 친구에게 코드리뷰를 부탁했다. [dojinkimm](https://github.com/dojinkimm) 👍👍 